# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.11.1
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

# +
from datetime import datetime, timedelta
import numpy as np

import pandas as pd
import matplotlib.pyplot as plt
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster
from sklearn.cluster import AgglomerativeClustering
from sklearn import preprocessing


from dataset.settings import DB_CONNECTION_STRING
from dataset.data_source.db_query import get_cpu_query
from dataset.data_source.dataframe import auto_interval_cpu_mean_df
from auxiliar.auxiliary_tools import save_a_cluster_small_single_alias_rolling_mean,\
                                    figures_to_html_stacked_and_side_by_side_from_folder


# -

# ### Fetch DB records

# +
# %%time

# Set interval & filters
query_params = {
    # 'day', 'hour', 'minute'
    'interval': 'minute',
    # datetime
    'start_date': datetime.now() - timedelta(weeks =1),
    # datetime
    'end_date': None,
    # 'windows', 'linux'
    'os': None,
    # List of host names
    'machines_to_include': None,
    # List of host names
    'machines_to_exclude': None,
    # Max number of records to fetch
    'limit': None
}

query = get_cpu_query(DB_CONNECTION_STRING, **query_params)
records = query.all()




# ### Load in dataframe
# -

df0 = pd.DataFrame(records, columns=['start_time', 'alias', 'os', 'per_CPU_use'])

df0 = df0.groupby('alias').agg({'per_CPU_use':[('mean','mean'),('std','std')]}).dropna()
df0

#Normalizing data
x = df0.values #returns a numpy array
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
df = pd.DataFrame(x_scaled)
df

X = df.to_numpy()
X

# +
labels = range(1, len(df)+1)
labels = df0.index.values
plt.figure(figsize=(10, 7))
plt.subplots_adjust(bottom=0.1)
plt.scatter(X[:,0],X[:,1], label='True Position')

for label, x, y in zip(labels, X[:, 0], X[:, 1]):
    plt.annotate(
        label,
        xy=(x, y), xytext=(-3, 3),
        textcoords='offset points', ha='right', va='bottom')
plt.show()

# +
linked = linkage(X, 'single')

labelList = range(1, len(df)+1)
labelList = df0.index.values

# plt.figure(figsize=(100, 70),dpi=200)
plt.figure(figsize=(15, 15),dpi=100)
plt.title('Dendrogram without truncation')
P = dendrogram(linked,
            orientation='top',
            labels=labelList,
            distance_sort='descending',
            show_leaf_counts=True)
plt.savefig('test2.png')
plt.show()

# +
Z = linkage(X, 'single')
# plt.figure(figsize=(50, 35),dpi=200)
plt.figure(figsize=(20, 15))
plt.title('Hierarchical Clustering Dendrogram (truncated)')
plt.xlabel('sample index')
plt.ylabel('distance')

dendrogram(
    Z,
    truncate_mode='lastp',  # show only the last p merged clusters
    p=120,  # show only the last p merged clusters
#     show_leaf_counts=False,  # otherwise numbers in brackets are counts
    labels=labelList,
    distance_sort='descending',
    leaf_rotation=90.,
    leaf_font_size=12.,
    show_contracted=True,  # to get a distribution impression in truncated branches
)
plt.show()

# -

def fancy_dendrogram(*args, **kwargs):
    max_d = kwargs.pop('max_d', None)
    if max_d and 'color_threshold' not in kwargs:
        kwargs['color_threshold'] = max_d
    annotate_above = kwargs.pop('annotate_above', 0)

    ddata = dendrogram(*args, **kwargs)

    if not kwargs.get('no_plot', False):
        plt.title('Hierarchical Clustering Dendrogram (truncated)')
        plt.xlabel('sample index or (cluster size)')
        plt.ylabel('distance')
        for i, d, c in zip(ddata['icoord'], ddata['dcoord'], ddata['color_list']):
            x = 0.5 * sum(i[1:3])
            y = d[1]
            if y > annotate_above:
                plt.plot(x, y, 'o', c=c)
                plt.annotate("%.3g" % y, (x, y), xytext=(0, -5),
                             textcoords='offset points',
                             va='top', ha='center')
        if max_d:
            plt.axhline(y=max_d, c='k')
    return ddata


plt.figure(figsize=(20, 15))
fancy_dendrogram(
    Z,
    truncate_mode='lastp',
    p=120,
    labels=labelList,
    leaf_rotation=90.,
    distance_sort='descending',
    leaf_font_size=12.,
    show_contracted=True,
#     annotate_above=10,  # useful in small plots so annotations don't overlap
)
plt.show()

# +
plt.figure(figsize=(20, 15))
max_d = 0.0206 # max_d as in max_distance
max_d = 0.026
max_d = 0.0143
max_d = 0.018
# max_d = 0.00701

dendo = fancy_dendrogram(
    Z,
    truncate_mode='lastp',
    p=120,
    labels=labelList,
    leaf_rotation=90.,
    distance_sort='descending',
    leaf_font_size=12.,
    show_contracted=True,
#     annotate_above=10,
    max_d=max_d,  # plot a horizontal cut-off line
)
plt.show()
# -

max_d = 0.0206 #gives 308 mach in the same class
max_d = 0.018
clusters = fcluster(Z, max_d, criterion='distance')
len(set(clusters))

for i in range(len(set(clusters))):
    print("cluster {0}: size = {1}".format(i,len(clusters[(clusters==i)])))

# +
#get alias of cluster 36
cluster1_atemp = df0[clusters==36].index.values
len(cluster1_atemp)

cluster2_atemp = df0[clusters==36].index.values
len(cluster2_atemp)

# +
#Compare to temporal clustering

df_nkmeans = pd.read_csv('Results/Clustering results-windows_clustering_fresh_data_normalized_data_best_version/merged_df_3kmeans.csv')
# -

cluster1_temp = df_nkmeans[df_nkmeans.y_pred==0].alias.values

print("alias from atemporal C1 not present in temporal C1: \n", np.setdiff1d(cluster1_atemp,cluster1_temp))
print()
print("alias from temporal C1 not present in atemporal C1: \n", np.setdiff1d(cluster1_temp,cluster1_atemp))

# +
# #Plot those 173 machines found in atemporal cluster 
df_nkmeans_group_of_int = df_nkmeans[df_nkmeans.alias.isin(cluster1_atemp)]
df = pd.read_csv('auxiliar/df/df_from10-04on.csv')
save_a_cluster_small_single_alias_rolling_mean(df,df_nkmeans_group_of_int,folder_name='Atemporal Clustering',note= 'Cluster1_atemp')

figures_to_html_stacked_and_side_by_side_from_folder(folder_name='Atemporal Clustering/Cluster1_atemp', filename='Atemporal Clustering/atemporal_clustering1.html')
# -

# ### do DENDROGRAM FOR CLUSTER 1 ALONE

df1 = df[clusters==36]
alias_c1 = df0[clusters==36].index
X1 = X[clusters==36]
Z1 = linkage(X1, 'single')
labelList1=labelList[clusters==36]

plt.figure(figsize=(20, 15),dpi=100)
plt.title('Dendrogram without truncation')
dendrogram(
    Z1,
    labels=labelList1,
    leaf_rotation=90.,
    distance_sort='descending',
    leaf_font_size=12.,
    show_contracted=True,
#     annotate_above=10,  # useful in small plots so annotations don't overlap
)
plt.show()

plt.figure(figsize=(20, 15))
fancy_dendrogram(
    Z1,
    truncate_mode='lastp',
    p=70,
    labels=labelList1,
    leaf_rotation=120.,
    distance_sort='descending',
    leaf_font_size=12.,
    show_contracted=True,
#     annotate_above=10,  # useful in small plots so annotations don't overlap
)
plt.show()

max_d = 0.0108
plt.figure(figsize=(20, 15))
fancy_dendrogram(
    Z1,
    truncate_mode='lastp',
    p=70,
    labels=labelList1,
    leaf_rotation=120.,
    distance_sort='descending',
    leaf_font_size=12.,
    show_contracted=True,
#     annotate_above=10,  # useful in small plots so annotations don't overlap
    max_d=max_d,  # plot a horizontal cut-off line
)
plt.show()

max_d = 0.0108
clusters_c1 = fcluster(Z1, max_d, criterion='distance')
len(set(clusters))

for i in range(len(set(clusters_c1))):
    print("cluster {0}: size = {1}".format(i,len(clusters_c1[(clusters_c1==i)])))

(labelList1[clusters_c1==6])

# ## Agglomerative clustering

cluster = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')
cluster.fit_predict(X)

plt.scatter(X[:,0],X[:,1], c=cluster.labels_,  cmap='rainbow',)
plt.xlim(-1, 25)
plt.ylim(-1, 22)

plt.scatter(X[:,0],X[:,1], c=cluster.labels_  ,cmap='rainbow')
plt.xlim(-1, 25)
plt.ylim(-1, 22)

# ## analyse

len(df[cluster.labels_==1])

a1 = list(df[cluster.labels_==1].index.values)
len(a1)

df_nkmeans = pd.read_csv('Results/Clustering results-windows_nagios_all_data/df_3kmeans.csv')

a2 = list(df_nkmeans[df_nkmeans.y_pred==0].alias.values)
len(a2)

list1_as_set = set(a1)
intersection = list1_as_set.intersection(a2)
len(intersection)

181/229


207/292


